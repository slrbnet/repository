<!DOCTYPE html>
<html lang="en">
<head>
        <meta charset="utf-8" />
        <meta name="generator" content="Pelican" />
        <title>SLRB - analysis</title>
        <link rel="stylesheet" href="/theme/css/main.css" />
        <link rel="icon" href="https://slrb.net/theme/images/icons/slrb.svg" type="image/x-icon">
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.2.1/jquery.min.js"></script>
	<script>
    		$(function(){
        		$('a').each(function(){
            			if ($(this).prop('href') == window.location.href) {
                			$(this).addClass('active'); $(this).parents('li').addClass('active');
            			}
        		});
    		});
	</script>

</head>

<body id="index" class="home">
        <header id="banner" class="body">
                <div><img src="https://www.slrb.net/theme/images/icons/slrb.svg" height="30px"/>&nbsp;&nbsp;&nbsp;<h1>Speech and Language Resource Bank</h1></div>
                <div class="topnav">
                                <a href="/pages/home.html">home</a>
                                <a href="/category/analysis.html">analysis</a>
                                <a href="/category/data.html">data</a>
                                <a href="/category/education.html">education</a>
                                <a href="/category/experimentation.html">experimentation</a>
			
  			<input type="text" placeholder="search (coming soon)">
		</div>
        </header>
	<br>
	<div class="note_header">
			<span class="fa fa-unlock-alt"></span> open&nbsp;&nbsp;
			<span class="fa fa-check-circle"></span> documented&nbsp;&nbsp;
	</div>
        <div class="note">
	        <h1><a href="/NAF.html" rel="bookmark" title="Permalink to Nasalization from Acoustic Features (NAF)">Nasalization from Acoustic Features (NAF)</a></h1>
		<h4> R code implementing a methodology for the automatic measurement of vowel nasalization from acoustic data. </h4>
                <strong>Authors:</strong>&nbsp;                                          <a class="url fn" href="/author/christopher-carignan.html">Christopher Carignan</a>
 <br>
                <strong>Updated:</strong>&nbsp; 2021-02-04 <br>
            <!-- <br> -->
		<strong>Source:</strong>&nbsp; <a href="https://github.com/ChristopherCarignan/NAF/">https://github.com/ChristopherCarignan/NAF/</a><br>
                <strong>Keywords:</strong>&nbsp;                                         <a href="/tag/nasalization.html">nasalization</a>,&nbsp; 
                                        <a href="/tag/phonetics.html">phonetics</a>,&nbsp; 
                                        <a href="/tag/machine-learning.html">machine-learning</a>,&nbsp; 
                                        <a href="/tag/mfcc.html">MFCC</a>,&nbsp; 
                                        <a href="/tag/acoustics.html">acoustics</a>,&nbsp; 
                                        <a href="/tag/r.html">R</a> 
        </div>
        
        <br>
        

	<div class="note_header">
			<span class="fa fa-unlock-alt"></span> open&nbsp;&nbsp;
			<span class="fa fa-check-circle"></span> documented&nbsp;&nbsp;
	</div>
        <div class="note">
	        <h1><a href="/SemDis.html" rel="bookmark" title="Permalink to SemDis">SemDis</a></h1>
		<h4> SemDis uses advances in natural language processing to automatically determine how closely associated texts are to each other. Higher SemDis scores indicate two texts are less related, that is, they are more distantly related ideas or concepts. </h4>
                <strong>Authors:</strong>&nbsp;                                          <a class="url fn" href="/author/dan-johnson-roger-beaty.html">Dan Johnson & Roger Beaty</a>
 <br>
                <strong>Updated:</strong>&nbsp; 2020-02-11 <br>
            <!-- <br> -->
		<strong>Source:</strong>&nbsp; <a href="http://semdis.wlu.psu.edu/">http://semdis.wlu.psu.edu/</a><br>
                <strong>Keywords:</strong>&nbsp;                                         <a href="/tag/language.html">language</a>,&nbsp; 
                                        <a href="/tag/semantics.html">semantics</a>,&nbsp; 
                                        <a href="/tag/word-recognition.html">word-recognition</a>,&nbsp; 
                                        <a href="/tag/english.html">English</a> 
        </div>
        
        <br>
        

	<div class="note_header">
			<span class="fa fa-unlock-alt"></span> open&nbsp;&nbsp;
	</div>
        <div class="note">
	        <h1><a href="/auditory-grouping-cues.html" rel="bookmark" title="Permalink to Auditory Grouping Cues">Auditory Grouping Cues</a></h1>
		<h4> Here, we derive auditory grouping cues by measuring and summarizing statistics of natural sound features. </h4>
                <strong>Authors:</strong>&nbsp;                                          <a class="url fn" href="/author/wiktor-mlynarski.html">Wiktor Młynarski</a>,&nbsp;
                                        <a class="url fn" href="/author/josh-h-mcdermott.html">Josh H. McDermott</a>
 <br>
                <strong>Updated:</strong>&nbsp; 2019-12-10 <br>
            <!-- <br> -->
		<strong>Source:</strong>&nbsp; <a href="http://mcdermottlab.mit.edu/grouping_statistics/index.html">http://mcdermottlab.mit.edu/grouping_statistics/index.html</a><br>
                <strong>Keywords:</strong>&nbsp;                                         <a href="/tag/sensory.html">sensory</a>,&nbsp; 
                                        <a href="/tag/audition.html">audition</a>,&nbsp; 
                                        <a href="/tag/frequency.html">frequency</a>,&nbsp; 
                                        <a href="/tag/harmony.html">harmony</a> 
        </div>
        
        <br>
        

	<div class="note_header">
			<span class="fa fa-unlock-alt"></span> open&nbsp;&nbsp;
	</div>
        <div class="note">
	        <h1><a href="/illusory-texture.html" rel="bookmark" title="Permalink to Illusory Texture Demos">Illusory Texture Demos</a></h1>
		<h4> Here you will find some sound examples demonstrating the phenomenon of "illusory sound texture." </h4>
                <strong>Authors:</strong>&nbsp;                                          <a class="url fn" href="/author/richard-mcwalter-and-josh-mcdermott.html">Richard McWalter and Josh McDermott</a>
 <br>
                <strong>Updated:</strong>&nbsp; 2019-11-11 <br>
            <!-- <br> -->
		<strong>Source:</strong>&nbsp; <a href="http://mcdermottlab.mit.edu/textcont.html">http://mcdermottlab.mit.edu/textcont.html</a><br>
                <strong>Keywords:</strong>&nbsp;                                         <a href="/tag/sound-texture.html">sound-texture</a>,&nbsp; 
                                        <a href="/tag/perception.html">perception</a>,&nbsp; 
                                        <a href="/tag/speech.html">speech</a>,&nbsp; 
                                        <a href="/tag/music.html">music</a> 
        </div>
        
        <br>
        

	<div class="note_header">
			<span class="fa fa-unlock-alt"></span> open&nbsp;&nbsp;
	</div>
        <div class="note">
	        <h1><a href="/CRIE.html" rel="bookmark" title="Permalink to Chinese Readability Index Explorer (CRIE)">Chinese Readability Index Explorer (CRIE)</a></h1>
		<h4> The Chinese Readability Index Explorer (CRIE) is composed of four subsystems and incorporates 82 multilevel linguistic features. CRIE is able to conduct the major tasks of segmentation, syntactic parsing, and feature extraction. </h4>
                <strong>Authors:</strong>&nbsp;                                          <a class="url fn" href="/author/yao-ting-sung.html">Yao-Ting Sung</a>,&nbsp;
                                        <a class="url fn" href="/author/tao-hsing-chang.html">Tao-Hsing Chang</a>,&nbsp;
                                        <a class="url fn" href="/author/wei-chun-lin.html">Wei-Chun Lin</a>,&nbsp;
                                        <a class="url fn" href="/author/kuan-sheng-hsieh.html">Kuan-Sheng Hsieh</a>,&nbsp;
                                        <a class="url fn" href="/author/kuo-en-chang.html">Kuo-En Chang</a>
 <br>
                <strong>Updated:</strong>&nbsp; 2019-02-11 <br>
            <!-- <br> -->
		<strong>Source:</strong>&nbsp; <a href="http://www.chinesereadability.net/CRIE/?LANG=CHT">http://www.chinesereadability.net/CRIE/?LANG=CHT</a><br>
                <strong>Keywords:</strong>&nbsp;                                         <a href="/tag/linguistics.html">linguistics</a>,&nbsp; 
                                        <a href="/tag/syntax.html">syntax</a>,&nbsp; 
                                        <a href="/tag/phonetics.html">phonetics</a>,&nbsp; 
                                        <a href="/tag/machine-learning.html">machine-learning</a>,&nbsp; 
                                        <a href="/tag/chinese.html">Chinese</a> 
        </div>
        
        <br>
        

	<div class="note_header">
			<span class="fa fa-unlock-alt"></span> open&nbsp;&nbsp;
	</div>
        <div class="note">
	        <h1><a href="/model-match.html" rel="bookmark" title="Permalink to Model-Matched Sounds">Model-Matched Sounds</a></h1>
		<h4> Cochleograms and sound files are shown for example stimuli from the model-matching experiment. </h4>
                <strong>Authors:</strong>&nbsp;                                          <a class="url fn" href="/author/sam-v-norman-haignere-josh-h-mcdermott.html">Sam V. Norman-Haignere & Josh H. McDermott</a>
 <br>
                <strong>Updated:</strong>&nbsp; 2018-12-03 <br>
            <!-- <br> -->
		<strong>Source:</strong>&nbsp; <a href="http://mcdermottlab.mit.edu/svnh/model-matching/Stimuli_from_Model-Matching_Experiment.html">http://mcdermottlab.mit.edu/svnh/model-matching/Stimuli_from_Model-Matching_Experiment.html</a><br>
                <strong>Keywords:</strong>&nbsp;                                         <a href="/tag/audition.html">audition</a>,&nbsp; 
                                        <a href="/tag/sensory.html">sensory</a>,&nbsp; 
                                        <a href="/tag/auditory-cortex.html">auditory-cortex</a>,&nbsp; 
                                        <a href="/tag/neuroscience.html">neuroscience</a>,&nbsp; 
                                        <a href="/tag/english.html">English</a> 
        </div>
        
        <br>
        

	<div class="note_header">
			<span class="fa fa-unlock-alt"></span> open&nbsp;&nbsp;
	</div>
        <div class="note">
	        <h1><a href="/inharmonic-speech-segregation.html" rel="bookmark" title="Permalink to Inharmonic Speech Segregation">Inharmonic Speech Segregation</a></h1>
		<h4> Inharmonic speech demos showing sound segregation. </h4>
                <strong>Authors:</strong>&nbsp;                                          <a class="url fn" href="/author/sara-popham.html">Sara Popham</a>,&nbsp;
                                        <a class="url fn" href="/author/dana-boebinger.html">Dana Boebinger</a>,&nbsp;
                                        <a class="url fn" href="/author/dan-p-w-ellis.html">Dan P. W. Ellis</a>,&nbsp;
                                        <a class="url fn" href="/author/hideki-kawahara.html">Hideki Kawahara</a>,&nbsp;
                                        <a class="url fn" href="/author/josh-h-mcdermott.html">Josh H. McDermott</a>
 <br>
                <strong>Updated:</strong>&nbsp; 2018-05-29 <br>
            <!-- <br> -->
		<strong>Source:</strong>&nbsp; <a href="http://mcdermottlab.mit.edu/inharmonic_speech_examples/index.html">http://mcdermottlab.mit.edu/inharmonic_speech_examples/index.html</a><br>
                <strong>Keywords:</strong>&nbsp;                                         <a href="/tag/sound-sources.html">sound-sources</a>,&nbsp; 
                                        <a href="/tag/brain.html">brain</a>,&nbsp; 
                                        <a href="/tag/frequency.html">frequency</a>,&nbsp; 
                                        <a href="/tag/harmonics.html">harmonics</a>,&nbsp; 
                                        <a href="/tag/english.html">English</a> 
        </div>
        
        <br>
        

	<div class="note_header">
			<span class="fa fa-unlock-alt"></span> open&nbsp;&nbsp;
	</div>
        <div class="note">
	        <h1><a href="/texture-time-averaging.html" rel="bookmark" title="Permalink to Texture-Time Averaging">Texture-Time Averaging</a></h1>
		<h4> Audio files showing the adaptive and selective time-averaging of auditory scenes. </h4>
                <strong>Authors:</strong>&nbsp;                                          <a class="url fn" href="/author/richard-mcwalter-josh-mcdermott.html">Richard McWalter & Josh McDermott</a>
 <br>
                <strong>Updated:</strong>&nbsp; 2018-05-07 <br>
            <!-- <br> -->
		<strong>Source:</strong>&nbsp; <a href="http://mcdermottlab.mit.edu/textint.html">http://mcdermottlab.mit.edu/textint.html</a><br>
                <strong>Keywords:</strong>&nbsp;                                         <a href="/tag/perception.html">perception</a>,&nbsp; 
                                        <a href="/tag/sensory-input.html">sensory-input</a>,&nbsp; 
                                        <a href="/tag/audition.html">audition</a> 
        </div>
        
        <br>
        

	<div class="note_header">
			<span class="fa fa-unlock-alt"></span> open&nbsp;&nbsp;
	</div>
        <div class="note">
	        <h1><a href="/schema-learning.html" rel="bookmark" title="Permalink to Schema Learning for the Cocktail Party Problem">Schema Learning for the Cocktail Party Problem</a></h1>
		<h4> The cocktail party problem requires listeners to infer individual sound </h4>
                <strong>Authors:</strong>&nbsp;                                          <a class="url fn" href="/author/kevin-jp-woods-josh-h-mcdermott.html">Kevin J.P. Woods & Josh H. McDermott</a>
 <br>
                <strong>Updated:</strong>&nbsp; 2018-04-03 <br>
            <!-- <br> -->
		<strong>Source:</strong>&nbsp; <a href="http://mcdermottlab.mit.edu/schema_learning/index.html">http://mcdermottlab.mit.edu/schema_learning/index.html</a><br>
                <strong>Keywords:</strong>&nbsp;                                         <a href="/tag/sound-sources.html">sound-sources</a>,&nbsp; 
                                        <a href="/tag/audition.html">audition</a>,&nbsp; 
                                        <a href="/tag/schema.html">schema</a> 
        </div>
        
        <br>
        

	<div class="note_header">
			<span class="fa fa-unlock-alt"></span> open&nbsp;&nbsp;
			<span class="fa fa-check-circle"></span> documented&nbsp;&nbsp;
	</div>
        <div class="note">
	        <h1><a href="/CLEESE.html" rel="bookmark" title="Permalink to Combinatorial Expressive Speech Engine">Combinatorial Expressive Speech Engine</a></h1>
		<h4> C.L.E.E.S.E. (Combinatorial Expressive Speech Engine) is a tool designed to generate an infinite number of natural-sounding, expressive variations around an original speech recording. </h4>
                <strong>Authors:</strong>&nbsp;                                          <a class="url fn" href="/author/juan-jose-burred.html">Juan José Burred</a>,&nbsp;
                                        <a class="url fn" href="/author/emmanuel-ponsot.html">Emmanuel Ponsot</a>
 <br>
                <strong>Updated:</strong>&nbsp; 2018-03-11 <br>
            <!-- <br> -->
		<strong>Source:</strong>&nbsp; <a href="http://cream.ircam.fr/?p=521">http://cream.ircam.fr/?p=521</a><br>
                <strong>Keywords:</strong>&nbsp;                                         <a href="/tag/language.html">language</a>,&nbsp; 
                                        <a href="/tag/speech.html">speech</a>,&nbsp; 
                                        <a href="/tag/pitch.html">pitch</a>,&nbsp; 
                                        <a href="/tag/french.html">French</a>,&nbsp; 
                                        <a href="/tag/english.html">English</a>,&nbsp; 
                                        <a href="/tag/japanese.html">Japanese</a> 
        </div>
        
        <br>
        
<p class="paginator">
        <a href="/category/analysis.html">&#8647;</a>
        <a href="/category/analysis.html">&laquo;</a>
    Page 2 / 4
        <a href="/category/analysis3.html">&raquo;</a>
        <a href="/category/analysis4.html">&#8649;</a>
</p>


  
        <footer id="contentinfo" class="body">
                <!-- <address id="about" class="vcard body">
                Proudly powered by <a href="https://getpelican.com/">Pelican</a>, which takes great advantage of <a href="https://www.python.org/">Python</a>.
                </address>

                <p>The theme is by <a href="https://www.smashingmagazine.com/2009/08/designing-a-html-5-layout-from-scratch/">Smashing Magazine</a>, thanks!</p> -->
        </footer><!-- /#contentinfo -->

</body>

<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-8XWFESHEMV"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());  gtag('config', 'G-8XWFESHEMV');
</script>
  
</html>