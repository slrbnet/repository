<!DOCTYPE html>
<html lang="en">
<head>
        <meta charset="utf-8" />
        <meta name="generator" content="Pelican" />
        <title>SLRB</title>
        <link rel="stylesheet" href="/theme/css/main.css" />
        <link rel="icon" type="image/x-icon" href="theme/images/icons/slrb.svg">
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.2.1/jquery.min.js"></script>
	<script>
    		$(function(){
        		$('a').each(function(){
            			if ($(this).prop('href') == window.location.href) {
                			$(this).addClass('active'); $(this).parents('li').addClass('active');
            			}
        		});
    		});
	</script>

	<link rel="stylesheet" href="https://files.stork-search.net/basic.css" />
</head>

<body id="index" class="home">
        <header id="banner" class="body">
                <div><img src="https://www.slrb.net/theme/images/icons/slrb.svg" height="30px"/>&nbsp;&nbsp;&nbsp;<h1>Speech and Language Resource Bank</h1></div>
                <div class="topnav">
                                <a href="/pages/home.html">home</a>
                                <a href="/pages/search.html">search</a>
                                <a href="/category/analysis.html">analysis</a>
                                <a href="/category/data.html">data</a>
                                <a href="/category/education.html">education</a>
                                <a href="/category/experimentation.html">experimentation</a>
		</div>
        </header>
	<br>

<p class="paginator">
        <a href="/index.html"><i class="fa-solid fa-arrow-left-to-line"></i></a>
        <a href="/index2.html"><i class="fa-arrow-circle-left"></i></a>
    Page 3 / 9
        <a href="/index4.html"><i class="fa-arrow-circle-right"></i></a>
        <a href="/index9.html"><i class="fa-solid fa-arrow-right-to-line"></i></a>
</p>
    
    <br>
	<div class="note_header">
			<span class="fa fa-unlock-alt"></span> open&nbsp;&nbsp;
	</div>
        <div class="note">
	        <h1><a href="/acoustics-vibration-animations.html" rel="bookmark" title="Permalink to Acoustics and Vibration Animations">Acoustics and Vibration Animations</a></h1>
		<h4> Animations illustrating acoustics, vibration, and wave phenomena. </h4>
                <strong>Authors:</strong>&nbsp;                                          <a class="url fn" href="/author/daniel-a-russell.html">Daniel A. Russell</a>
 <br>
                <strong>Updated:</strong>&nbsp; 2020-11-28 <br>
            <!-- <br> -->
		<strong>Source:</strong>&nbsp; <a href="https://www.acs.psu.edu/drussell/demos.html">https://www.acs.psu.edu/drussell/demos.html</a><br>
                <strong>Keywords:</strong>&nbsp;                                         <a href="/tag/acoustics.html">acoustics</a>,&nbsp; 
                                        <a href="/tag/vibration.html">vibration</a>,&nbsp; 
                                        <a href="/tag/waves.html">waves</a>,&nbsp; 
                                        <a href="/tag/animations.html">animations</a>,&nbsp; 
                                        <a href="/tag/sound.html">sound</a> 
        </div>

        <br>

	<div class="note_header">
			<span class="fa fa-unlock-alt"></span> open&nbsp;&nbsp;
	</div>
        <div class="note">
	        <h1><a href="/LHQ3.html" rel="bookmark" title="Permalink to Language History Questionnaire (version 3)">Language History Questionnaire (version 3)</a></h1>
		<h4> Language history questionnaire (LHQ) is an important tool for assessing language learners' linguistic background, the context and habits of language use, proficiency in multiple languages, and the dominance and cultural identity of the languages acquired. </h4>
                <strong>Authors:</strong>&nbsp;                                          <a class="url fn" href="/author/ping-li.html">Ping Li</a>,&nbsp;
                                        <a class="url fn" href="/author/sara-sepanski.html">Sara Sepanski</a>,&nbsp;
                                        <a class="url fn" href="/author/xiaowei-zhao.html">Xiaowei Zhao</a>,&nbsp;
                                        <a class="url fn" href="/author/fan-zhang.html">Fan Zhang</a>,&nbsp;
                                        <a class="url fn" href="/author/erlfang-tsai.html">Erlfang Tsai</a>,&nbsp;
                                        <a class="url fn" href="/author/brendan-puls.html">Brendan Puls</a>,&nbsp;
                                        <a class="url fn" href="/author/anya-yu.html">Anya Yu</a>
 <br>
                <strong>Updated:</strong>&nbsp; 2020-11-05 <br>
            <!-- <br> -->
		<strong>Source:</strong>&nbsp; <a href="https://lhq3.herokuapp.com/">https://lhq3.herokuapp.com/</a><br>
                <strong>Keywords:</strong>&nbsp;                                         <a href="/tag/language.html">language</a>,&nbsp; 
                                        <a href="/tag/linguistics.html">linguistics</a>,&nbsp; 
                                        <a href="/tag/multilinguialism.html">multilinguialism</a>,&nbsp; 
                                        <a href="/tag/education.html">education</a> 
        </div>

        <br>

	<div class="note_header">
			<span class="fa fa-unlock-alt"></span> open&nbsp;&nbsp;
	</div>
        <div class="note">
	        <h1><a href="/ASL-CDI.html" rel="bookmark" title="Permalink to ASL-CDI 2.0">ASL-CDI 2.0</a></h1>
		<h4> The ASL-CDI 2.0 is an updated American Sign Language adaptation of the MacArthur Bates Communicative Development Inventory. It is an assessment of early vocabulary knowledge in children learning American Sign Language. </h4>
                <strong>Authors:</strong>&nbsp;                                          <a class="url fn" href="/author/naomi-caselli.html">Naomi Caselli</a>,&nbsp;
                                        <a class="url fn" href="/author/jennie-pyers.html">Jennie Pyers</a>,&nbsp;
                                        <a class="url fn" href="/author/amy-lieberman.html">Amy Lieberman</a>
 <br>
                <strong>Updated:</strong>&nbsp; 2020-10-05 <br>
            <!-- <br> -->
		<strong>Source:</strong>&nbsp; <a href="https://www.aslcdi.org/">https://www.aslcdi.org/</a><br>
                <strong>Keywords:</strong>&nbsp;                                         <a href="/tag/vocabulary.html">vocabulary</a>,&nbsp; 
                                        <a href="/tag/language-development.html">language-development</a>,&nbsp; 
                                        <a href="/tag/communication.html">communication</a>,&nbsp; 
                                        <a href="/tag/american-sign-language.html">American-Sign-Language</a>,&nbsp; 
                                        <a href="/tag/english.html">English</a> 
        </div>

        <br>

	<div class="note_header">
			<span class="fa fa-unlock-alt"></span> open&nbsp;&nbsp;
	</div>
        <div class="note">
	        <h1><a href="/Corpus-NGT.html" rel="bookmark" title="Permalink to Corpus of Dutch Sign Language">Corpus of Dutch Sign Language</a></h1>
		<h4> The NGT is a collection data from deaf signers using Sign Language of the Netherlands (NGT). </h4>
                <strong>Authors:</strong>&nbsp;                                          <a class="url fn" href="/author/onno-crasborn.html">Onno Crasborn</a>,&nbsp;
                                        <a class="url fn" href="/author/inge-zwitserlood.html">Inge Zwitserlood</a>,&nbsp;
                                        <a class="url fn" href="/author/johan-ros.html">Johan Ros</a>
 <br>
                <strong>Updated:</strong>&nbsp; 2020-10-05 <br>
            <!-- <br> -->
		<strong>Source:</strong>&nbsp; <a href="https://www.corpusngt.nl/">https://www.corpusngt.nl/</a><br>
                <strong>Keywords:</strong>&nbsp;                                         <a href="/tag/language.html">language</a>,&nbsp; 
                                        <a href="/tag/communication.html">communication</a>,&nbsp; 
                                        <a href="/tag/dutch-sign-language.html">Dutch-Sign-Language</a> 
        </div>

        <br>

	<div class="note_header">
			<span class="fa fa-unlock-alt"></span> open&nbsp;&nbsp;
	</div>
        <div class="note">
	        <h1><a href="/ERT.html" rel="bookmark" title="Permalink to The Emotion Recognition Task">The Emotion Recognition Task</a></h1>
		<h4> The ERT is a computerized task to assess the perception of facial expressions. The task presents morphed facial expressions that gradually increase in intensity. </h4>
                <strong>Authors:</strong>&nbsp;                                          <a class="url fn" href="/author/barbara-montagne.html">Barbara Montagne</a>,&nbsp;
                                        <a class="url fn" href="/author/roy-kessels.html">Roy Kessels</a>,&nbsp;
                                        <a class="url fn" href="/author/david-perrett.html">David Perrett</a>,&nbsp;
                                        <a class="url fn" href="/author/edward-de-haan.html">Edward de Haan</a>
 <br>
                <strong>Updated:</strong>&nbsp; 2020-10-05 <br>
            <!-- <br> -->
		<strong>Source:</strong>&nbsp; <a href="https://www.emotionrecognitiontask.com/">https://www.emotionrecognitiontask.com/</a><br>
                <strong>Keywords:</strong>&nbsp;                                         <a href="/tag/emotion.html">emotion</a>,&nbsp; 
                                        <a href="/tag/psychology.html">psychology</a>,&nbsp; 
                                        <a href="/tag/neuropsychology.html">neuropsychology</a>,&nbsp; 
                                        <a href="/tag/cognition.html">cognition</a>,&nbsp; 
                                        <a href="/tag/dutch.html">Dutch</a>,&nbsp; 
                                        <a href="/tag/english.html">English</a>,&nbsp; 
                                        <a href="/tag/german.html">German</a>,&nbsp; 
                                        <a href="/tag/french.html">French</a>,&nbsp; 
                                        <a href="/tag/spanish.html">Spanish</a>,&nbsp; 
                                        <a href="/tag/finnish.html">Finnish</a>,&nbsp; 
                                        <a href="/tag/italian.html">Italian</a>,&nbsp; 
                                        <a href="/tag/russian.html">Russian</a>,&nbsp; 
                                        <a href="/tag/lithuanian.html">Lithuanian</a>,&nbsp; 
                                        <a href="/tag/greek.html">Greek</a>,&nbsp; 
                                        <a href="/tag/portuguese.html">Portuguese</a>,&nbsp; 
                                        <a href="/tag/turkish.html">Turkish</a> 
        </div>

        <br>

	<div class="note_header">
			<span class="fa fa-unlock-alt"></span> open&nbsp;&nbsp;
			<span class="fa fa-check-circle"></span> documented&nbsp;&nbsp;
	</div>
        <div class="note">
	        <h1><a href="/SemDis.html" rel="bookmark" title="Permalink to SemDis">SemDis</a></h1>
		<h4> SemDis uses advances in natural language processing to automatically determine how closely associated texts are to each other. Higher SemDis scores indicate two texts are less related, that is, they are more distantly related ideas or concepts. </h4>
                <strong>Authors:</strong>&nbsp;                                          <a class="url fn" href="/author/dan-johnson-roger-beaty.html">Dan Johnson & Roger Beaty</a>
 <br>
                <strong>Updated:</strong>&nbsp; 2020-10-05 <br>
            <!-- <br> -->
		<strong>Source:</strong>&nbsp; <a href="http://semdis.wlu.psu.edu/">http://semdis.wlu.psu.edu/</a><br>
                <strong>Keywords:</strong>&nbsp;                                         <a href="/tag/language.html">language</a>,&nbsp; 
                                        <a href="/tag/semantics.html">semantics</a>,&nbsp; 
                                        <a href="/tag/word-recognition.html">word-recognition</a>,&nbsp; 
                                        <a href="/tag/english.html">English</a> 
        </div>

        <br>

	<div class="note_header">
			<span class="fa fa-unlock-alt"></span> open&nbsp;&nbsp;
			<span class="fa fa-check-circle"></span> documented&nbsp;&nbsp;
	</div>
        <div class="note">
	        <h1><a href="/StimuliApp.html" rel="bookmark" title="Permalink to StimuliApp">StimuliApp</a></h1>
		<h4> StimuliApp is a free app designed to create psychophysical tests with precise timing on iOS and iPadOS devices. </h4>
                <strong>Authors:</strong>&nbsp;                                          <a class="url fn" href="/author/rafael-marin-campos.html">Rafael Marin-Campos</a>,&nbsp;
                                        <a class="url fn" href="/author/joseph-dalmau.html">Joseph Dalmau</a>,&nbsp;
                                        <a class="url fn" href="/author/albert-compte.html">Albert Compte</a>,&nbsp;
                                        <a class="url fn" href="/author/daniel-linares.html">Daniel Linares</a>
 <br>
                <strong>Updated:</strong>&nbsp; 2020-10-05 <br>
            <!-- <br> -->
		<strong>Source:</strong>&nbsp; <a href="https://www.stimuliapp.com/">https://www.stimuliapp.com/</a><br>
                <strong>Keywords:</strong>&nbsp;                                         <a href="/tag/psychophysics.html">psychophysics</a>,&nbsp; 
                                        <a href="/tag/experiment.html">experiment</a>,&nbsp; 
                                        <a href="/tag/audition.html">audition</a>,&nbsp; 
                                        <a href="/tag/visual-stimulation.html">visual-stimulation</a> 
        </div>

        <br>

	<div class="note_header">
			<span class="fa fa-unlock-alt"></span> open&nbsp;&nbsp;
	</div>
        <div class="note">
	        <h1><a href="/VietSLP.html" rel="bookmark" title="Permalink to VietSLP">VietSLP</a></h1>
		<h4> The San Diego State University Bilingual Development in Context research lab has created and validated a set of assessment tools for the Vietnamese language. </h4>
                <strong>Authors:</strong>&nbsp;                                          <a class="url fn" href="/author/giang-t-pham.html">Giang T. Pham</a>,&nbsp;
                                        <a class="url fn" href="/author/quynh-dam.html">Quynh Dam</a>,&nbsp;
                                        <a class="url fn" href="/author/kerry-ebert.html">Kerry Ebert</a>,&nbsp;
                                        <a class="url fn" href="/author/ben-pham.html">Ben Pham</a>,&nbsp;
                                        <a class="url fn" href="/author/van-pham.html">Van Pham</a>,&nbsp;
                                        <a class="url fn" href="/author/hien-hoang.html">Hien Hoang</a>,&nbsp;
                                        <a class="url fn" href="/author/linh-pham.html">Linh Pham</a>,&nbsp;
                                        <a class="url fn" href="/author/ngoc-tran.html">Ngoc Tran</a>,&nbsp;
                                        <a class="url fn" href="/author/kristine-thuy-dinh.html">Kristine Thuy Dinh</a>,&nbsp;
                                        <a class="url fn" href="/author/son-pham.html">Son Pham</a>,&nbsp;
                                        <a class="url fn" href="/author/thong-le.html">Thong Le</a>,&nbsp;
                                        <a class="url fn" href="/author/chris-nguyen.html">Chris Nguyen</a>
 <br>
                <strong>Updated:</strong>&nbsp; 2020-10-05 <br>
            <!-- <br> -->
		<strong>Source:</strong>&nbsp; <a href="https://vietslp.sdsu.edu/">https://vietslp.sdsu.edu/</a><br>
                <strong>Keywords:</strong>&nbsp;                                         <a href="/tag/speech-pathology.html">speech-pathology</a>,&nbsp; 
                                        <a href="/tag/language.html">language</a>,&nbsp; 
                                        <a href="/tag/bilingual.html">bilingual</a>,&nbsp; 
                                        <a href="/tag/vietnamese.html">Vietnamese</a> 
        </div>

        <br>

	<div class="note_header">
			<span class="fa fa-unlock-alt"></span> open&nbsp;&nbsp;
	</div>
        <div class="note">
	        <h1><a href="/storybook-apps.html" rel="bookmark" title="Permalink to VL2 Storybook Apps">VL2 Storybook Apps</a></h1>
		<h4> Stories told in sign language by fluent Deaf storytellers. Easy & accessible navigation designed for children. Page-by-page sign language videos supporting the printed sentences text. Rich interactive narrative with direct English to ASL vocabulary video translation. 120+ new vocabulary words with each app. Parents can learn new ASL signs along with their child. </h4>
                <strong>Authors:</strong>&nbsp;                                          <a class="url fn" href="/author/motion-light-lab.html">Motion Light Lab</a>
 <br>
                <strong>Updated:</strong>&nbsp; 2020-10-05 <br>
            <!-- <br> -->
		<strong>Source:</strong>&nbsp; <a href="https://vl2storybookapps.com/digital-library">https://vl2storybookapps.com/digital-library</a><br>
                <strong>Keywords:</strong>&nbsp;                                         <a href="/tag/language.html">language</a>,&nbsp; 
                                        <a href="/tag/education.html">education</a>,&nbsp; 
                                        <a href="/tag/bilingual.html">bilingual</a>,&nbsp; 
                                        <a href="/tag/american-sign-language.html">American-Sign-Language</a>,&nbsp; 
                                        <a href="/tag/english.html">English</a> 
        </div>

        <br>

	<div class="note_header">
			<span class="fa fa-unlock-alt"></span> open&nbsp;&nbsp;
			<span class="fa fa-check-circle"></span> documented&nbsp;&nbsp;
	</div>
        <div class="note">
	        <h1><a href="/STEP-Experiments.html" rel="bookmark" title="Permalink to System for Teaching Experimental Psychology">System for Teaching Experimental Psychology</a></h1>
		<h4> The goal of STEP was to facilitate the use of E-Prime in various learning contexts. Part of this goal was achieved by creating and hosting a large set of classic experiments implemented in E-Prime. </h4>
                <strong>Authors:</strong>&nbsp;                                          <a class="url fn" href="/author/brian-macwhinney.html">Brian MacWhinney</a>,&nbsp;
                                        <a class="url fn" href="/author/susan-campbell.html">Susan Campbell</a>,&nbsp;
                                        <a class="url fn" href="/author/ping-li.html">Ping Li</a>,&nbsp;
                                        <a class="url fn" href="/author/chris-schunn.html">Chris Schunn</a>,&nbsp;
                                        <a class="url fn" href="/author/and-james-st-james.html">and James St. James</a>
 <br>
                <strong>Updated:</strong>&nbsp; 2020-09-23 <br>
            <!-- <br> -->
		<strong>Source:</strong>&nbsp; <a href="https://support.pstnet.com/hc/en-us/categories/360003738794-STEP-Experiments">https://support.pstnet.com/hc/en-us/categories/360003738794-STEP-Experiments</a><br>
                <strong>Keywords:</strong>&nbsp;                                         <a href="/tag/experiment.html">experiment</a>,&nbsp; 
                                        <a href="/tag/data-collection.html">data-collection</a>,&nbsp; 
                                        <a href="/tag/psychology.html">psychology</a>,&nbsp; 
                                        <a href="/tag/e-prime.html">E-Prime</a> 
        </div>

        <br>

	<div class="note_header">
			<span class="fa fa-unlock-alt"></span> open&nbsp;&nbsp;
			<span class="fa fa-check-circle"></span> documented&nbsp;&nbsp;
	</div>
        <div class="note">
	        <h1><a href="/BITTSy.html" rel="bookmark" title="Permalink to BITTSy: Behavioral Infant & Toddler Testing System">BITTSy: Behavioral Infant & Toddler Testing System</a></h1>
		<h4> BITTSy is capable of running key infant behavioral testing paradigms, including Headturn Preference Procedure [HPP], Preferential Looking, and Visual Fixation/Habituation, through the same interface. </h4>
                <strong>Authors:</strong>&nbsp;                                          <a class="url fn" href="/author/rochelle-newman.html">Rochelle Newman</a>,&nbsp;
                                        <a class="url fn" href="/author/emily-shroads.html">Emily Shroads</a>,&nbsp;
                                        <a class="url fn" href="/author/elizabeth-johnson.html">Elizabeth Johnson</a>,&nbsp;
                                        <a class="url fn" href="/author/ruth-tincoff.html">Ruth Tincoff</a>,&nbsp;
                                        <a class="url fn" href="/author/kris-onishi.html">Kris Onishi</a>,&nbsp;
                                        <a class="url fn" href="/author/giovanna-morini.html">Giovanna Morini</a>
 <br>
                <strong>Updated:</strong>&nbsp; 2020-09-04 <br>
            <!-- <br> -->
		<strong>Source:</strong>&nbsp; <a href="http://langdev.umd.edu/bittsy/">http://langdev.umd.edu/bittsy/</a><br>
                <strong>Keywords:</strong>&nbsp;                                         <a href="/tag/child-development.html">child-development</a>,&nbsp; 
                                        <a href="/tag/software.html">software</a>,&nbsp; 
                                        <a href="/tag/experiment.html">experiment</a>,&nbsp; 
                                        <a href="/tag/behavior.html">behavior</a>,&nbsp; 
                                        <a href="/tag/english.html">English</a> 
        </div>

        <br>

	<div class="note_header">
			<span class="fa fa-unlock-alt"></span> open&nbsp;&nbsp;
	</div>
        <div class="note">
	        <h1><a href="/IRQ.html" rel="bookmark" title="Permalink to The Internal Representations Questionnaire">The Internal Representations Questionnaire</a></h1>
		<h4> The Internal Representations Questionnaire (IRQ) is a measure designed to quantify the subjective format of thought. There are four factors in the questionnaire namely; visual imagery, propensity to verbalize, representational manipulation and orthographic imagery. </h4>
                <strong>Authors:</strong>&nbsp;                                          <a class="url fn" href="/author/hettie-roebuck.html">Hettie Roebuck</a>,&nbsp;
                                        <a class="url fn" href="/author/pierce-edmiston.html">Pierce Edmiston</a>,&nbsp;
                                        <a class="url fn" href="/author/gary-lupyan.html">Gary Lupyan</a>
 <br>
                <strong>Updated:</strong>&nbsp; 2020-07-14 <br>
            <!-- <br> -->
		<strong>Source:</strong>&nbsp; <a href="https://osf.io/8rdzh/">https://osf.io/8rdzh/</a><br>
                <strong>Keywords:</strong>&nbsp;                                         <a href="/tag/psychology.html">psychology</a>,&nbsp; 
                                        <a href="/tag/cognition.html">cognition</a>,&nbsp; 
                                        <a href="/tag/questionnaire.html">questionnaire</a>,&nbsp; 
                                        <a href="/tag/language.html">language</a>,&nbsp; 
                                        <a href="/tag/english.html">English</a> 
        </div>

        <br>

	<div class="note_header">
			<span class="fa fa-unlock-alt"></span> open&nbsp;&nbsp;
	</div>
        <div class="note">
	        <h1><a href="/ModelTalker.html" rel="bookmark" title="Permalink to The Model Talker System">The Model Talker System</a></h1>
		<h4> The ModelTalker System converts plain English text to speech. It uses recorded speech (either from a prospective SGD user or from a voice donor chosen by or for the SGD user) to create a unique synthetic voice. </h4>
                <strong>Authors:</strong>&nbsp;                                          <a class="url fn" href="/author/h-timothy-bunnell.html">H. Timothy Bunnell</a>,&nbsp;
                                        <a class="url fn" href="/author/jason-lilley.html">Jason Lilley</a>,&nbsp;
                                        <a class="url fn" href="/author/matthew-buzzell.html">Matthew Buzzell</a>,&nbsp;
                                        <a class="url fn" href="/author/maxwell-schmid.html">Maxwell Schmid</a>,&nbsp;
                                        <a class="url fn" href="/author/bill-moyers.html">Bill Moyers</a>,&nbsp;
                                        <a class="url fn" href="/author/derek-freer.html">Derek Freer</a>
 <br>
                <strong>Updated:</strong>&nbsp; 2020-06-25 <br>
            <!-- <br> -->
		<strong>Source:</strong>&nbsp; <a href="https://www.modeltalker.org/">https://www.modeltalker.org/</a><br>
                <strong>Keywords:</strong>&nbsp;                                         <a href="/tag/language.html">language</a>,&nbsp; 
                                        <a href="/tag/communication.html">communication</a>,&nbsp; 
                                        <a href="/tag/speech.html">speech</a>,&nbsp; 
                                        <a href="/tag/phonology.html">phonology</a>,&nbsp; 
                                        <a href="/tag/morphology.html">morphology</a>,&nbsp; 
                                        <a href="/tag/english.html">English</a> 
        </div>

        <br>

	<div class="note_header">
			<span class="fa fa-unlock-alt"></span> open&nbsp;&nbsp;
			<span class="fa fa-check-circle"></span> documented&nbsp;&nbsp;
	</div>
        <div class="note">
	        <h1><a href="/headphone-check.html" rel="bookmark" title="Permalink to Headphone Check">Headphone Check</a></h1>
		<h4> This code implements a headphone screening task intended to facilitate web-based experiments employing auditory stimuli. </h4>
                <strong>Authors:</strong>&nbsp;                                          <a class="url fn" href="/author/kevin-jp-woods.html">Kevin J.P. Woods</a>,&nbsp;
                                        <a class="url fn" href="/author/max-h-siegel.html">Max H. Siegel</a>,&nbsp;
                                        <a class="url fn" href="/author/james-traer.html">James Traer</a>,&nbsp;
                                        <a class="url fn" href="/author/josh-h-mcdermott.html">Josh H. McDermott</a>,&nbsp;
                                        <a class="url fn" href="/author/ray-gonzalez.html">Ray Gonzalez</a>,&nbsp;
                                        <a class="url fn" href="/author/kelsey-allen.html">Kelsey Allen</a>
 <br>
                <strong>Updated:</strong>&nbsp; 2020-06-02 <br>
            <!-- <br> -->
		<strong>Source:</strong>&nbsp; <a href="https://github.com/mcdermottLab/HeadphoneCheck">https://github.com/mcdermottLab/HeadphoneCheck</a><br>
                <strong>Keywords:</strong>&nbsp;                                         <a href="/tag/audition.html">audition</a>,&nbsp; 
                                        <a href="/tag/experiment.html">experiment</a>,&nbsp; 
                                        <a href="/tag/stimuli.html">stimuli</a>,&nbsp; 
                                        <a href="/tag/pure-tone.html">pure-tone</a> 
        </div>

        <br>

	<div class="note_header">
			<span class="fa fa-unlock-alt"></span> open&nbsp;&nbsp;
			<span class="fa fa-check-circle"></span> documented&nbsp;&nbsp;
	</div>
        <div class="note">
	        <h1><a href="/spatial-orientation.html" rel="bookmark" title="Permalink to Spatial Orientation Test">Spatial Orientation Test</a></h1>
		<h4> On each trial of the SOT, people are shown an array of objects; they have to imagine being located at one object, facing a second object (the orienting cue). They must indicate the direction of a third object (the target object) by drawing a line from the center of the circle in the direction believed to be correct. </h4>
                <strong>Authors:</strong>&nbsp;                                          <a class="url fn" href="/author/alinda-friedman.html">Alinda Friedman</a>,&nbsp;
                                        <a class="url fn" href="/author/alexander-paul-boone.html">Alexander Paul Boone</a>,&nbsp;
                                        <a class="url fn" href="/author/bernd-kohler.html">Bernd Kohler</a>,&nbsp;
                                        <a class="url fn" href="/author/mary-hegarty.html">Mary Hegarty</a>
 <br>
                <strong>Updated:</strong>&nbsp; 2020-05-26 <br>
            <!-- <br> -->
		<strong>Source:</strong>&nbsp; <a href="https://osf.io/wq3kd/">https://osf.io/wq3kd/</a><br>
                <strong>Keywords:</strong>&nbsp;                                         <a href="/tag/psychology.html">psychology</a>,&nbsp; 
                                        <a href="/tag/experiment.html">experiment</a>,&nbsp; 
                                        <a href="/tag/spatial-ability.html">spatial-ability</a>,&nbsp; 
                                        <a href="/tag/perspective.html">perspective</a>,&nbsp; 
                                        <a href="/tag/english.html">English</a> 
        </div>

        <br>

	<div class="note_header">
			<span class="fa fa-unlock-alt"></span> open&nbsp;&nbsp;
			<span class="fa fa-check-circle"></span> documented&nbsp;&nbsp;
	</div>
        <div class="note">
	        <h1><a href="/ECP-L2.html" rel="bookmark" title="Permalink to The English Crowdsourcing Project (L2 speakers)">The English Crowdsourcing Project (L2 speakers)</a></h1>
		<h4> The English Crowdsourcing Project (L2) contains word recognition times for 61,851 English words in a Y/N vocabulary recognition task. </h4>
                <strong>Authors:</strong>&nbsp;                                          <a class="url fn" href="/author/marc-brysbaert.html">Marc Brysbaert</a>,&nbsp;
                                        <a class="url fn" href="/author/emmanuel-keuleers.html">Emmanuel Keuleers</a>,&nbsp;
                                        <a class="url fn" href="/author/pawel-mandera.html">Pawel Mandera</a>
 <br>
                <strong>Updated:</strong>&nbsp; 2020-05-18 <br>
            <!-- <br> -->
		<strong>Source:</strong>&nbsp; <a href="http://crr.ugent.be/programs-data/lexicon-projects">http://crr.ugent.be/programs-data/lexicon-projects</a><br>
                <strong>Keywords:</strong>&nbsp;                                         <a href="/tag/word-prevalence.html">word-prevalence</a>,&nbsp; 
                                        <a href="/tag/word-frequency.html">word-frequency</a>,&nbsp; 
                                        <a href="/tag/word-knowledge.html">word-knowledge</a>,&nbsp; 
                                        <a href="/tag/crowdsourcing.html">crowdsourcing</a>,&nbsp; 
                                        <a href="/tag/language-acquisition.html">language-acquisition</a>,&nbsp; 
                                        <a href="/tag/vocabulary.html">vocabulary</a> 
        </div>

        <br>

	<div class="note_header">
			<span class="fa fa-unlock-alt"></span> open&nbsp;&nbsp;
	</div>
        <div class="note">
	        <h1><a href="/COCA.html" rel="bookmark" title="Permalink to Corpus of Contemporary American English">Corpus of Contemporary American English</a></h1>
		<h4> The Corpus of Contemporary American English (COCA) is the only large, genre-balanced corpus of American English. </h4>
                <strong>Authors:</strong>&nbsp;                                          <a class="url fn" href="/author/mark-davies.html">Mark Davies</a>
 <br>
                <strong>Updated:</strong>&nbsp; 2020-03-05 <br>
            <!-- <br> -->
		<strong>Source:</strong>&nbsp; <a href="https://www.english-corpora.org/coca/">https://www.english-corpora.org/coca/</a><br>
                <strong>Keywords:</strong>&nbsp;                                         <a href="/tag/english.html">English</a>,&nbsp; 
                                        <a href="/tag/corpora.html">corpora</a>,&nbsp; 
                                        <a href="/tag/linguistics.html">linguistics</a>,&nbsp; 
                                        <a href="/tag/frequency-data.html">frequency-data</a>,&nbsp; 
                                        <a href="/tag/word-form.html">word-form</a> 
        </div>

        <br>

	<div class="note_header">
			<span class="fa fa-unlock-alt"></span> open&nbsp;&nbsp;
			<span class="fa fa-check-circle"></span> documented&nbsp;&nbsp;
	</div>
        <div class="note">
	        <h1><a href="/FLP.html" rel="bookmark" title="Permalink to The French Lexicon Project">The French Lexicon Project</a></h1>
		<h4> The French Lexicon Project contains lexical decision times for over 38,000 French words. </h4>
                <strong>Authors:</strong>&nbsp;                                          <a class="url fn" href="/author/ludovic-ferrand.html">Ludovic Ferrand</a>,&nbsp;
                                        <a class="url fn" href="/author/boris-new.html">Boris New</a>,&nbsp;
                                        <a class="url fn" href="/author/marc-brysbaert.html">Marc Brysbaert</a>,&nbsp;
                                        <a class="url fn" href="/author/emmanuel-keuleers.html">Emmanuel Keuleers</a>,&nbsp;
                                        <a class="url fn" href="/author/patrick-bonin.html">Patrick Bonin</a>,&nbsp;
                                        <a class="url fn" href="/author/alain-meot.html">Alain Meot</a>,&nbsp;
                                        <a class="url fn" href="/author/maria-augustinova.html">Maria Augustinova</a>,&nbsp;
                                        <a class="url fn" href="/author/christophe-pallier.html">Christophe Pallier</a>
 <br>
                <strong>Updated:</strong>&nbsp; 2020-02-03 <br>
            <!-- <br> -->
		<strong>Source:</strong>&nbsp; <a href="https://osf.io/f8kc4/">https://osf.io/f8kc4/</a><br>
                <strong>Keywords:</strong>&nbsp;                                         <a href="/tag/lexicon.html">lexicon</a>,&nbsp; 
                                        <a href="/tag/vocabulary.html">vocabulary</a>,&nbsp; 
                                        <a href="/tag/french.html">French</a>,&nbsp; 
                                        <a href="/tag/word-frequency.html">word-frequency</a>,&nbsp; 
                                        <a href="/tag/word-recognition.html">word-recognition</a> 
        </div>

        <br>

	<div class="note_header">
			<span class="fa fa-unlock-alt"></span> open&nbsp;&nbsp;
	</div>
        <div class="note">
	        <h1><a href="/auditory-grouping-cues.html" rel="bookmark" title="Permalink to Auditory Grouping Cues">Auditory Grouping Cues</a></h1>
		<h4> Here, we derive auditory grouping cues by measuring and summarizing statistics of natural sound features. </h4>
                <strong>Authors:</strong>&nbsp;                                          <a class="url fn" href="/author/wiktor-mlynarski.html">Wiktor MÅ‚ynarski</a>,&nbsp;
                                        <a class="url fn" href="/author/josh-h-mcdermott.html">Josh H. McDermott</a>
 <br>
                <strong>Updated:</strong>&nbsp; 2019-12-10 <br>
            <!-- <br> -->
		<strong>Source:</strong>&nbsp; <a href="http://mcdermottlab.mit.edu/grouping_statistics/index.html">http://mcdermottlab.mit.edu/grouping_statistics/index.html</a><br>
                <strong>Keywords:</strong>&nbsp;                                         <a href="/tag/sensory.html">sensory</a>,&nbsp; 
                                        <a href="/tag/audition.html">audition</a>,&nbsp; 
                                        <a href="/tag/frequency.html">frequency</a>,&nbsp; 
                                        <a href="/tag/harmony.html">harmony</a> 
        </div>

        <br>

	<div class="note_header">
			<span class="fa fa-unlock-alt"></span> open&nbsp;&nbsp;
	</div>
        <div class="note">
	        <h1><a href="/KEC.html" rel="bookmark" title="Permalink to The Karl Eberhards Corpus of spontaneously spoken southern German in dialogues: Audio and articulatory recordings">The Karl Eberhards Corpus of spontaneously spoken southern German in dialogues: Audio and articulatory recordings</a></h1>
		<h4> 40 one-hour recordings of two friends talking to each other. </h4>
                <strong>Authors:</strong>&nbsp;                                          <a class="url fn" href="/author/denis-arnold.html">Denis Arnold</a>,&nbsp;
                                        <a class="url fn" href="/author/fabian-tomaschek.html">Fabian Tomaschek</a>
 <br>
                <strong>Updated:</strong>&nbsp; 2019-11-29 <br>
            <!-- <br> -->
		<strong>Source:</strong>&nbsp; <a href="http://hdl.handle.net/11022/1009-0000-0007-DADB-D">http://hdl.handle.net/11022/1009-0000-0007-DADB-D</a><br>
                <strong>Keywords:</strong>&nbsp;                                         <a href="/tag/spontaneous-speech.html">spontaneous-speech</a>,&nbsp; 
                                        <a href="/tag/spoken-corpus.html">spoken-corpus</a>,&nbsp; 
                                        <a href="/tag/electromagnetic-articulography.html">electromagnetic-articulography</a>,&nbsp; 
                                        <a href="/tag/german.html">german</a> 
        </div>

        <br>


<p class="paginator">
        <a href="/index.html"><i class="fa-solid fa-arrow-left-to-line"></i></a>
        <a href="/index2.html"><i class="fa-arrow-circle-left"></i></a>
    Page 3 / 9
        <a href="/index4.html"><i class="fa-arrow-circle-right"></i></a>
        <a href="/index9.html"><i class="fa-solid fa-arrow-right-to-line"></i></a>
</p>

  
        <footer id="contentinfo" class="body">
                <!-- <address id="about" class="vcard body">
                Proudly powered by <a href="https://getpelican.com/">Pelican</a>, which takes great advantage of <a href="https://www.python.org/">Python</a>.
                </address>

                <p>The theme is by <a href="https://www.smashingmagazine.com/2009/08/designing-a-html-5-layout-from-scratch/">Smashing Magazine</a>, thanks!</p> -->
        </footer><!-- /#contentinfo -->

	<script src="https://files.stork-search.net/releases/v1.5.0/stork.js"></script>
	<script>
		stork.register("sitesearch", "/search-index.st")
	</script>
</body>

<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-8XWFESHEMV"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());  gtag('config', 'G-8XWFESHEMV');
</script>
  
</html>